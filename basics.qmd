# Basics {#sec-basics .unnumbered}

```{r}
#| child: "status.qmd"
```
```{r}
#| include: false
source("setup.R")
```



::: {.blockquote}
If the design of an experiment is faulty, any method of interpretation which makes it out to be decisive must be faulty too.

--Fisher, 1935, Design of Experiments
:::

Data is a resultant reality so any examination of the data to answer questions in a satisfying manner requires understanding of the origin of the data, i.e. **_how was the data collected and curated?_** If you don't know how the data originated, how do you know what population the sample represents? In the absence of understanding the origin of data, your interpretation can be flawed -- we've seen this with prediction algorithms trained on biased data, election outcome that was unexpected by many because the poll indicated otherwise, retracted articles due to fabricated data, and so on. You can dissect your data using myraids of different analysis but it'll do no good if your data is rubbish. Knowing the method of data collection and data curation doesn't guarantee your analysis will be better but it can raise your understanding of the limitation of your interpretation. 

Experimental data, as the name suggests, is data collected from an experiment. Unlike other methods of data collection, experimental data originate from a controlled environment where specific factors in the data are within the control of the experimenter. In other words, experimental data are unique in that we have control over how data is created. How to control these factors is what entails as _experimental design_.


There are many articles and books dedicated to explaining the concepts of experimental designs. This includes the seminal book by @Fisher1935-qc, @Bailey2008-gw, etc. This chapter presents an overview of the statistical concepts that are most pertinent in designing an experiment. 

Most experiments are comparative in nature, or more specifically, most experiments involve study of two or more experimental conditions in which the primary interest is to compare the outcome under the different conditions. You'll therefore find that most experiments in this book are **comparative experiments**. 

At the heart of each experiment, we are ultimately seeking confidence in any conclusion we are making from the analysis of the experimental data. What is perhaps not emphasised enough is that the **_experiments are human endeavours_**. Often there are multiple people involved in running experiments and a key challenge is to ensure each individual has sufficient understanding to play their role well.  We touch more on this in @sec-management. 

All experiments have a cost whether that be financial, resources, time or other. We can consider the **experimental cost** as a function of the ability to redo the experiment again. For example, if your experimental resources are based on examination of fossils and the fossils are destroyed in the experimental process, then the cost of the experiment is infinite -- you only have one chance to do the experiment -- so it's absolutely essential that you plan, design and execute the experiment well.

Doing an experiment well requires a good understanding of the subject matter so that the  potential sources of variation can be controlled or accounted for in the experimental design. Prior to the collection of data, the statistical component of an experiment tends to be focussed on the design of the experiment, i.e. how the treatments are assigned to experimental units under practical constrains to maximise the statistical information of interest. Under this consideration, the statistical problem for experimental design is often reduced to either a randomisation or an optimisation problem and the experimental context may be stripped away in the generation of the design using computer software. We discuss this in @sec-context, then describe a system that  encourages higher order thinking of the experimental design, termed the grammar of experimental designs, in @sec-grammar-ed, implemented as the `edibble` R-package and present how to get started with the `edibble` system to construct experimental design in @sec-edibble.

Before we get into the crux of the basics of the experimental design, consider the three scenarios below. Each scenario describes an experiment where technical details have been reduced so it doesn't serve as a distraction for now. For each scenario, try to see if you can identify what are the basic components to build the design of the experiment.
 
::: {.callout-note icon=false}

## `r eunit1()` Scenario 1: plant growth  

Microbes have a potential for promoting plant growth by increasing abiotic stress tolerance of the plant. An experiment is conducted to study three bacterial strains known for promoting plant growth under osmotic stress.

:::

::: {.callout-note icon=false}

## `r eunit2()` Scenario 2: wine tasting 

A large-scale experiment was conducted to discern whether expensive wines are good value for money. The experiment involved 450 individuals in a public tasting of expensive or inexpensive wine. The taster did not know whether they were tasting the expensive or inexpensive wine. 

:::

::: {.callout-note icon=false}

## `r eunit3()` Scenario 3: new classification method 

A new statistical method is proposed as a better alternative for classification of cellular type from single cell transcriptomics data. A number of simulations, based on a number of public benchmark  datasets, was carried out to compare the method under different metrics. 

:::
 













